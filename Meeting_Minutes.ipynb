{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ba8d4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"./.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5afdc3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_settings import BaseSettings\n",
    "\n",
    "class ModelConfig(BaseSettings):\n",
    "    gemini_api_key: str\n",
    "    model_name: str\n",
    "    temperature: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34729e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai.chat_models import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d21770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatModel(ChatGoogleGenerativeAI):\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__(\n",
    "            model=config.model_name,\n",
    "            temperature=config.temperature,\n",
    "            api_key=config.gemini_api_key\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e72a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Dict, Any\n",
    "import re, uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "214b920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionState(BaseModel):\n",
    "    transcript: str\n",
    "    chunks: List[Dict[str, Any]] = []\n",
    "    action_items: List[Dict[str, Any]] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a1fb625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chunks(text: str, max_chars: int = 3000) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Splits transcripts by speaker lines, keeps names + text\n",
    "    Return list of dicts {id, speaker, text}\"\"\"\n",
    "\n",
    "    chunks = []\n",
    "\n",
    "    while True:\n",
    "        if text:\n",
    "            txt_chunk = text[:max_chars]\n",
    "            text = text[max_chars:]\n",
    "        else:\n",
    "            print(\"No more text to process\")\n",
    "            break\n",
    "\n",
    "        block = re.split(r'(?=\\n[A-Z][a-z]+:)', txt_chunk)\n",
    "        if len(block) > 1:\n",
    "            chunk = \" \".join(block[:-1])\n",
    "            text = block[-1] + text\n",
    "        else:\n",
    "            chunk  = \"\".join(block)\n",
    "            text = None\n",
    "\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "\n",
    "        if not text:\n",
    "            break\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a3caffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_transcript(state: ActionState) -> ActionState:\n",
    "    chunks = split_into_chunks(state.transcript)\n",
    "    state.chunks = [{\"id\": str(uuid.uuid4()), \"text\": chunk} for chunk in chunks]\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0137310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "753cab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_actions(state: ActionState) -> ActionState:\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessagePromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "                You are an Meeting Minutes Assistant.\n",
    "                Given a meeting transcript, you will extract actionable tasks from the transcript.\n",
    "                Important: The 'owner' is the person RESPONSIBLE for the task, not the person who mentioned it.\n",
    "                \"\"\"\n",
    "            ),\n",
    "            HumanMessagePromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "                Given the following meeting transcript, extract all actionable tasks.\n",
    "                \n",
    "                Transcript:\n",
    "                {transcript}\n",
    "                \n",
    "                Return a JSON array in the following format:\n",
    "                [\n",
    "                  {{\"owner\": \"person_name\", \"task\": \"task_description\", \"due_date\": \"date_or_null\"}},\n",
    "                  {{\"owner\": \"person_name\", \"task\": \"task_description\", \"due_date\": \"date_or_null\"}}\n",
    "                ]\n",
    "                \n",
    "                Only return the JSON array, no other text or markdown formatting.\n",
    "                \"\"\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chat = ChatModel(ModelConfig())\n",
    "    lcel = (\n",
    "        prompt\n",
    "        | chat\n",
    "    )\n",
    "\n",
    "\n",
    "    action_items = []\n",
    "    for chunk in state.chunks:\n",
    "        text = chunk[\"text\"]\n",
    "        response = lcel.invoke({\"transcript\": text})\n",
    "\n",
    "        try:\n",
    "            import json\n",
    "            # Parse the JSON response and extend the action_items list\n",
    "            parsed_items = json.loads(response.content)\n",
    "            if isinstance(parsed_items, list):\n",
    "                action_items.extend(parsed_items)\n",
    "            else:\n",
    "                action_items.append(parsed_items)\n",
    "        except json.JSONDecodeError:\n",
    "            action_items.append({\"error\": \"Failed to parse JSON response\", \"response\": response.content[:200]})\n",
    "\n",
    "    state.action_items = action_items\n",
    "\n",
    "    return state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f418e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "workflow = StateGraph(\n",
    "    state_schema=ActionState,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b91c19be",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_node(\"ingest_transcript\", ingest_transcript)\n",
    "workflow.add_node(\"extract_actions\", extract_actions)\n",
    "\n",
    "workflow.add_edge(START, \"ingest_transcript\")\n",
    "workflow.add_edge(\"ingest_transcript\", \"extract_actions\")\n",
    "workflow.add_edge(\"extract_actions\", END)\n",
    "\n",
    "meeting_agent = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3988fd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = \"\"\"\n",
    "    Alice: We need the quarterly report ready by Friday.\n",
    "    Bob: I'll prepare the financial section.\n",
    "    Priya: I'll set up a follow-up meeting next week.\n",
    "    \"\"\"\n",
    "\n",
    "output = meeting_agent.invoke({\"transcript\": transcript})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef782baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Meeting Minutes Processing Results ===\n",
      "\n",
      "Transcript processed into 1 chunks\n",
      "Extracted 2 action items:\n",
      "\n",
      "--- Action Items ---\n",
      "1. Owner: Bob\n",
      "   Task: Prepare the financial section (of the quarterly report)\n",
      "   Due Date: Friday\n",
      "\n",
      "2. Owner: Priya\n",
      "   Task: Set up a follow-up meeting\n",
      "   Due Date: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "print(\"=== Meeting Minutes Processing Results ===\")\n",
    "print(f\"\\nTranscript processed into {len(output['chunks'])} chunks\")\n",
    "print(f\"Extracted {len(output['action_items'])} action items:\")\n",
    "print(\"\\n--- Action Items ---\")\n",
    "for i, item in enumerate(output['action_items'], 1):\n",
    "    if 'error' in item:\n",
    "        print(f\"{i}. ERROR: {item}\")\n",
    "    else:\n",
    "        print(f\"{i}. Owner: {item['owner']}\")\n",
    "        print(f\"   Task: {item['task']}\")\n",
    "        print(f\"   Due Date: {item['due_date']}\")\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend_api (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
